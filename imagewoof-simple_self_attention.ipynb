{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/sdoria/SimpleSelfAttention/blob/master/Imagenette%20Simple%20Self%20Attention.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "warnings.filterwarnings('ignore')\n",
    "path = Path('../data/imagenette/imagenette-160')\n",
    "sys.path.append(\"dev/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMAGEWOOF_160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ubuntu/.fastai/data/imagewoof-160/train/n02093754'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imagewoof-160/train/n02088364'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imagewoof-160/train/n02089973'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imagewoof-160/train/n02087394'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imagewoof-160/train/n02111889'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imagewoof-160/train/n02099601'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imagewoof-160/train/n02105641'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imagewoof-160/train/n02086240'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imagewoof-160/train/n02115641'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imagewoof-160/train/models'),\n",
       " PosixPath('/home/ubuntu/.fastai/data/imagewoof-160/train/n02096294')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(True, \n",
    "                      False,\n",
    "                      max_rotate=15,\n",
    "                      max_zoom=1.3,\n",
    "                      max_lighting=0.3,\n",
    "                      max_warp=0.2,\n",
    "                      p_affine=0.5,\n",
    "                      p_lighting=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 128\n",
    "data = (ImageList.from_folder(path=path/'train')    \n",
    "        .random_split_by_pct(0.1)\n",
    "        .label_from_folder()\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=64)\n",
    "        .normalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test data\n",
    "test_data = (ImageList.from_folder(path=path/'val')\n",
    "            .no_split()\n",
    "            .label_from_folder()\n",
    "            .transform(None, size=sz)\n",
    "            .databunch(bs=64)\n",
    "            .normalize(data.stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.add_test(test_data.train_ds.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (11209 items)\n",
       "x: ImageList\n",
       "Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128)\n",
       "y: CategoryList\n",
       "n02093754,n02093754,n02093754,n02093754,n02093754\n",
       "Path: /home/ubuntu/.fastai/data/imagewoof-160/train;\n",
       "\n",
       "Valid: LabelList (1245 items)\n",
       "x: ImageList\n",
       "Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128)\n",
       "y: CategoryList\n",
       "n02087394,n02087394,n02111889,n02115641,n02105641\n",
       "Path: /home/ubuntu/.fastai/data/imagewoof-160/train;\n",
       "\n",
       "Test: LabelList (500 items)\n",
       "x: ImageList\n",
       "Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128),Image (3, 128, 128)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: /home/ubuntu/.fastai/data/imagewoof-160/train"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet34'\n",
    "arch = getattr(models, model_name)\n",
    "\n",
    "learn_callbacks = [TerminateOnNaNCallback()]\n",
    "learn_callback_fns = [partial(EarlyStoppingCallback, monitor='accuracy', mode='max', patience=5),\n",
    "                      partial(SaveModelCallback, monitor='accuracy', mode='max',\n",
    "                              name='baseline'),\n",
    "                      partial(CSVLogger, filename=f'../logs/{model_name}')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlphaPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor(\n",
    "    [\n",
    "        [[1,2,3,4,5],\n",
    "        [1,2,3,4,5]],\n",
    "        \n",
    "        [[1,2,3,4,5],\n",
    "        [1,2,3,4,5]],\n",
    "        \n",
    "        [[1,2,3,4,5],\n",
    "        [1,2,3,4,5]],\n",
    "    ]\n",
    ").float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaPool(nn.Module):\n",
    "    def __init__(self, alpha:float=1., eps:float=1e-8):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(tensor([0.]))   \n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x): \n",
    "        \"Creates alpha-pooling features from a CNN like feature map\"\n",
    "        self.alpha.data.sigmoid_()\n",
    "        b,fn,h,w = x.shape\n",
    "        x = x.view(b,fn,h*w)\n",
    "        x = (((((torch.sign(x)*(torch.abs(x)**(1))).permute(0,2,1).contiguous())\n",
    "            .unsqueeze(2)) * x.permute(0,2,1).contiguous().unsqueeze(3))\n",
    "            ).view(b,h*w,-1)\n",
    "        x = F.normalize(x.mean(dim=1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 262144])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_pool = AlphaPool()\n",
    "x1 = torch.randn((32,512,4,4))\n",
    "f = alpha_pool(x1); f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlphaPool()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.9807e-03,  4.3009e-03,  6.4197e-05,  ..., -1.9180e-03,\n",
       "        -5.8776e-04,  8.3033e-03])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.learner import cnn_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_head(nf:int, nc:int, lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5,\n",
    "                concat_pool:bool=True,alpha_pool:bool=True, bn_final:bool=False):\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and about `nc` classes.\"\n",
    "    lin_ftrs = [nf, 512, nc] if lin_ftrs is None else [nf] + lin_ftrs + [nc]\n",
    "    ps = listify(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n",
    "    pool = AlphaPool() if alpha_pool else pool\n",
    "    layers = [pool, Flatten()]\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n",
    "        layers += bn_drop_lin(ni, no, True, p, actn)\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def create_cnn_model(base_arch:Callable, nc:int, cut:Union[int,Callable]=None, pretrained:bool=True,\n",
    "        lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5, custom_head:Optional[nn.Module]=None,\n",
    "        split_on:Optional[SplitFuncOrIdxList]=None, bn_final:bool=False, concat_pool:bool=True):\n",
    "    \"Create custom convnet architecture\"\n",
    "    body = create_body(base_arch, pretrained, cut)\n",
    "    if custom_head is None:\n",
    "        nf = num_features_model(nn.Sequential(*body.children())) * (2 if concat_pool else 1)\n",
    "        head = create_head(nf, nc, lin_ftrs, ps=ps, concat_pool=concat_pool, bn_final=bn_final)\n",
    "    else: head = custom_head\n",
    "    return nn.Sequential(body, head)\n",
    "\n",
    "def cnn_learner(data:DataBunch, base_arch:Callable, cut:Union[int,Callable]=None, pretrained:bool=True,\n",
    "                lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5, custom_head:Optional[nn.Module]=None,\n",
    "                split_on:Optional[SplitFuncOrIdxList]=None, bn_final:bool=False, init=nn.init.kaiming_normal_,\n",
    "                concat_pool:bool=True, **kwargs:Any)->Learner:\n",
    "    \"Build convnet style learner.\"\n",
    "    meta = cnn_config(base_arch)\n",
    "    model = create_cnn_model(base_arch, data.c, cut, pretrained, lin_ftrs, ps=ps, custom_head=custom_head,\n",
    "        split_on=split_on, bn_final=bn_final, concat_pool=concat_pool)\n",
    "    learn = Learner(data, model, **kwargs)\n",
    "    learn.split(split_on or meta['split'])\n",
    "    if pretrained: learn.freeze()\n",
    "    if init: apply_init(model[1], init)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_head = create_head(512**2, data.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(data=data, \n",
    "                    custom_head=custom_head,\n",
    "                    base_arch=arch,\n",
    "                    pretrained=False, \n",
    "                    metrics=[accuracy],\n",
    "                    callbacks=learn_callbacks,\n",
    "                    callback_fns=learn_callback_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AlphaPool()\n",
       "  (1): Flatten()\n",
       "  (2): BatchNorm1d(262144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Dropout(p=0.25)\n",
       "  (4): Linear(in_features=262144, out_features=512, bias=True)\n",
       "  (5): ReLU(inplace)\n",
       "  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Dropout(p=0.5)\n",
       "  (8): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# learn.lr_find()\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.mixup(0.2)\n",
    "# learn.to_fp16()\n",
    "# learn.loss_func = LabelSmoothingCrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='50', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      2.00% [1/50 01:48<1:28:35]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.385319</td>\n",
       "      <td>2.081367</td>\n",
       "      <td>0.236948</td>\n",
       "      <td>01:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='22' class='' max='175', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      12.57% [22/175 00:11<01:17 2.3714]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with accuracy value: 0.23694778978824615.\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(50, max_lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.callbacks = []\n",
    "def TTA_score(load_pth='baseline'):\n",
    "    learn.load(load_pth)\n",
    "    preds = learn.TTA(ds_type=DatasetType.Test)\n",
    "    test_preds = torch.argmax(preds[0], 1)\n",
    "    test_preds = to_np(test_preds)\n",
    "    test_labels = test_data.train_ds.y.items\n",
    "    print(f\"top1 acc: {np.mean(test_labels == test_preds)}\")\n",
    "\n",
    "def non_TTA_score(load_pth='baseline'):\n",
    "    learn.load(load_pth)\n",
    "    preds = learn.get_preds(ds_type=DatasetType.Test)\n",
    "    test_preds = torch.argmax(preds[0], 1)\n",
    "    test_preds = to_np(test_preds)\n",
    "    test_labels = test_data.train_ds.y.items\n",
    "    print(f\"top1 acc: {np.mean(test_labels == test_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_TTA_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Tricks \n",
    "\n",
    "https://arxiv.org/pdf/1812.01187.pdf\n",
    "\n",
    "#### 1. Large batch \n",
    "\n",
    "**Large Batch Size Training**\n",
    "\n",
    "- Increase learning rate as lr x bs_new/bs_old\n",
    "\n",
    "**Warmup with first m batches**\n",
    "\n",
    "- Linearly increase learning rate to lr in first m batches \n",
    "\n",
    "**Set $\\gamma$ = 0 in BN layers in ResBlocks**\n",
    "\n",
    "- Mimics a network with less parameters at the beginning of training\n",
    "\n",
    "**No wd (L2 reg) in bias, or BN params $\\gamma, \\beta$**\n",
    "\n",
    "#### 2. Low Precision\n",
    "\n",
    "**FP16 Training**\n",
    "\n",
    "#### 3. ResNet Tweaks\n",
    "\n",
    "ResNetB, ResNetC, ResNetD...\n",
    "\n",
    "#### 4. Cosine Annealing LR\n",
    "\n",
    "#### 5. Label Smoothing\n",
    "\n",
    "LabelSmoothingCrossEntropy()\n",
    "\n",
    "#### 6. Student Teacher\n",
    "\n",
    "$(p,softmax(z)) + T^{2}(softmax(r/T),softmax(z/T))$\n",
    "\n",
    "#### 7. Mixup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
